[
  {
    "id": "2401.12345",
    "submitter": null,
    "authors": "Shixiong Wang, Wei Dai, Geoffrey Ye Li",
    "title": "Distributionally Robust Receive Combining",
    "comments": "It is proved that the ridge and kernel ridge regression methods in machine learning are distributionally robust against diagonal perturbation in feature covariance, which reveals that channel estimation is not a necessary operation.",
    "journal_ref": null,
    "doi": "10.1109/TSP.2025.3582082",
    "report_no": null,
    "categories": "",
    "license": null,
    "abstract": "This article investigates signal estimation in wireless transmission (i.e., receive combining) from the perspective of statistical machine learning, where the transmit signals may be from an integrated sensing and communication system; that is, 1) signals may be not only discrete constellation points but also arbitrary complex values; 2) signals may be spatially correlated. Particular attention is paid to handling various uncertainties such as the uncertainty of the transmit signal covariance, the uncertainty of the channel matrix, the uncertainty of the channel noise covariance, the existence of channel impulse noises, the non-ideality of the power amplifiers, and the limited sample size of pilots. To proceed, a distributionally robust receive combining framework that is insensitive to the above uncertainties is proposed, which reveals that channel estimation is not a necessary operation. For optimal linear estimation, the proposed framework includes several existing combiners as special cases such as diagonal loading and eigenvalue thresholding. For optimal nonlinear estimation, estimators are limited in reproducing kernel Hilbert spaces and neural network function spaces, and corresponding uncertainty-aware solutions (e.g., kernelized diagonal loading) are derived. In addition, we prove that the ridge and kernel ridge regression methods in machine learning are distributionally robust against diagonal perturbation in feature covariance.",
    "versions": [],
    "update_date": "2024",
    "authors_parsed": []
  },
  {
    "id": "2312.09876",
    "submitter": null,
    "authors": "Aditya Parikh",
    "title": "Automatic Image Colourizer",
    "comments": null,
    "journal_ref": null,
    "doi": "10.48550/arXiv.2312.09876",
    "report_no": null,
    "categories": "",
    "license": null,
    "abstract": "In this project we have designed and described a model which colourize a gray-scale image, with no human intervention. We propose a fully automatic process of colouring and re-colouring faded or gray-scale image with vibrant and pragmatic colours. We have used Convolutional Neural Network to hallucinate input images and feed-forwarded by training thousands of images. This approach results in trailblazing results.",
    "versions": [],
    "update_date": "2023",
    "authors_parsed": []
  },
  {
    "id": "2311.18805",
    "submitter": null,
    "authors": "Qi Cao, Takeshi Kojima, Yutaka Matsuo, Yusuke Iwasawa",
    "title": "Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text",
    "comments": "Novel experimental insights are presented into the resilience of LLMs, particularly GPT-4, when subjected to extensive character-level permutations, and it is counter-intuitive that LLMs can exhibit such resilience despite severe disruption to input tokenization caused by scrambled text.",
    "journal_ref": null,
    "doi": "10.48550/arXiv.2311.18805",
    "report_no": null,
    "categories": "",
    "license": null,
    "abstract": "While Large Language Models (LLMs) have achieved remarkable performance in many tasks, much about their inner workings remains unclear. In this study, we present novel experimental insights into the resilience of LLMs, particularly GPT-4, when subjected to extensive character-level permutations. To investigate this, we first propose the Scrambled Bench, a suite designed to measure the capacity of LLMs to handle scrambled input, in terms of both recovering scrambled sentences and answering questions given scrambled context. The experimental results indicate that most powerful LLMs demonstrate the capability akin to typoglycemia, a phenomenon where humans can understand the meaning of words even when the letters within those words are scrambled, as long as the first and last letters remain in place. More surprisingly, we found that only GPT-4 nearly flawlessly processes inputs with unnatural errors, even under the extreme condition, a task that poses significant challenges for other LLMs and often even for humans. Specifically, GPT-4 can almost perfectly reconstruct the original sentences from scrambled ones, decreasing the edit distance by 95%, even when all letters within each word are entirely scrambled. It is counter-intuitive that LLMs can exhibit such resilience despite severe disruption to input tokenization caused by scrambled text.",
    "versions": [],
    "update_date": "2023",
    "authors_parsed": []
  },
  {
    "id": "2310.12345",
    "submitter": null,
    "authors": "G. Hakim, David Osowiechi, Mehrdad Noori, Milad Cheraghalikhani, Ismail Ben Ayed, Christian Desrosiers",
    "title": "ClusT3: Information Invariant Test-Time Training",
    "comments": "This work proposes a novel unsupervised TTT technique based on the maximization of Mutual Information between multi-scale feature maps and a discrete latent representation, which can be integrated to the standard training as an auxiliary clustering task.",
    "journal_ref": null,
    "doi": "10.1109/ICCV51070.2023.00564",
    "report_no": null,
    "categories": "",
    "license": null,
    "abstract": "Deep Learning models have shown remarkable performance in a broad range of vision tasks. However, they are often vulnerable to domain shifts at test-time. Test-time training (TTT) methods have been developed in an attempt to mitigate these vulnerabilities, where a secondary task is solved at training time, simultaneously with the main task, to be later used as an self-supervised proxy task at test-time. In this work, we propose a novel unsupervised TTT technique based on the maximization of Mutual Information between multi-scale feature maps and a discrete latent representation, which can be integrated to the standard training as an auxiliary clustering task. Experimental results demonstrate competitive classification performance on different popular test-time adaptation benchmarks. The code can be found at: https://github.com/dosowiechi/ClusT3.git",
    "versions": [],
    "update_date": "2023",
    "authors_parsed": []
  },
  {
    "id": "2309.08743",
    "submitter": null,
    "authors": "Himanshu Thakur, Soumitri Chattopadhyay",
    "title": "Active Learning for Fine-Grained Sketch-Based Image Retrieval",
    "comments": "This work proposes a novel active learning sampling technique that drastically minimises the need for drawing photo sketches by utilising the relationship between the existing photo-sketch pair to a photo that does not have its sketch and augmenting this relation with its intermediate representations.",
    "journal_ref": null,
    "doi": "10.48550/arXiv.2309.08743",
    "report_no": null,
    "categories": "",
    "license": null,
    "abstract": "The ability to retrieve a photo by mere free-hand sketching highlights the immense potential of Fine-grained sketch-based image retrieval (FG-SBIR). However, its rapid practical adoption, as well as scalability, is limited by the expense of acquiring faithful sketches for easily available photo counterparts. A solution to this problem is Active Learning, which could minimise the need for labeled sketches while maximising performance. Despite extensive studies in the field, there exists no work that utilises it for reducing sketching effort in FG-SBIR tasks. To this end, we propose a novel active learning sampling technique that drastically minimises the need for drawing photo sketches. Our proposed approach tackles the trade-off between uncertainty and diversity by utilising the relationship between the existing photo-sketch pair to a photo that does not have its sketch and augmenting this relation with its intermediate representations. Since our approach relies only on the underlying data distribution, it is agnostic of the modelling approach and hence is applicable to other cross-modal instance-level retrieval tasks as well. With experimentation over two publicly available fine-grained SBIR datasets ChairV2 and ShoeV2, we validate our approach and reveal its superiority over adapted baselines.",
    "versions": [],
    "update_date": "2023",
    "authors_parsed": []
  }
]